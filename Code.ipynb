{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akash1331/textSummarizer_major/blob/main/Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzvrXVUHusEZ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "POS4rhrHusEc"
      },
      "outputs": [],
      "source": [
        "# from attention import AttentionLayer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "R9cT5MJzusEe"
      },
      "outputs": [],
      "source": [
        "# pip install ipykernal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "EwPklsu4usEe"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy\n",
        "# !pip install pandas\n",
        "# !pip install tensorflow\n",
        "# !pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "vaQSHfyyusEf"
      },
      "outputs": [],
      "source": [
        "# !pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "JEGv-ixAusEf"
      },
      "outputs": [],
      "source": [
        "# !pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]\n"
      ],
      "metadata": {
        "id": "2hC4jUmYyrMc"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "xrIJNiDdusEg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqo416chusEg"
      },
      "source": [
        "# Data Read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "2qaCEkN3usEg"
      },
      "outputs": [],
      "source": [
        "# data=pd.read_csv(\"Dataset.csv\")\n",
        "data=pd.read_csv(\"Reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "FvaNz08fusEg",
        "outputId": "446654f0-5d3d-4736-e72b-9b8e9e8f11a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n",
              "\n",
              "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
              "0                       1      5  1303862400  Good Quality Dog Food   \n",
              "\n",
              "                                                                                                                                                                                                      Text  \n",
              "0  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ffe0d79-4211-48d7-94f6-03cbb5a73a34\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ffe0d79-4211-48d7-94f6-03cbb5a73a34')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ffe0d79-4211-48d7-94f6-03cbb5a73a34 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ffe0d79-4211-48d7-94f6-03cbb5a73a34');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "data.head(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "8mpdtRBIusEh"
      },
      "outputs": [],
      "source": [
        "data.drop_duplicates(subset=['Text'],inplace=True)\n",
        "#subset=['Text'] searches for duplicates only in the column with name Text(Last column)\n",
        "#inplace=true will cause all the rows which have same text value to be dropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "TF2IgLoMusEh"
      },
      "outputs": [],
      "source": [
        "data.dropna(axis=0,inplace=True)\n",
        "#this is the instruction to delete all rows with atleast one NaN values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd8tkjObusEh"
      },
      "source": [
        "# Data Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAd39dy6usEh",
        "outputId": "299c2ad0-c58b-475a-a068-a9835680f781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 393565 entries, 0 to 568453\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   Id                      393565 non-null  int64 \n",
            " 1   ProductId               393565 non-null  object\n",
            " 2   UserId                  393565 non-null  object\n",
            " 3   ProfileName             393565 non-null  object\n",
            " 4   HelpfulnessNumerator    393565 non-null  int64 \n",
            " 5   HelpfulnessDenominator  393565 non-null  int64 \n",
            " 6   Score                   393565 non-null  int64 \n",
            " 7   Time                    393565 non-null  int64 \n",
            " 8   Summary                 393565 non-null  object\n",
            " 9   Text                    393565 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 33.0+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdVd6bsIusEh"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "BOdaBeBhusEi"
      },
      "outputs": [],
      "source": [
        "# To remove unnecessary symbols we will define a dictionary for expanding the contractions\n",
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di8H8qyFusEi",
        "outputId": "33cfc201-68a5-485d-a44e-59fff69f1789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that\n",
        "#a search engine has been programmed to ignore, both when indexing entries for searching and\n",
        "#when retrieving them as the result of a search query.\n",
        "#To check the list of stopwords we use the following instruction\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "945E_XO8usEi",
        "outputId": "61a573ad-adc5-418c-909b-d86f193de1be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "stop_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBvmFXC1usEi"
      },
      "source": [
        "Defining function for test cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "islEIKhIusEj"
      },
      "outputs": [],
      "source": [
        "def text_cleaner(text,num):\n",
        "    String1 = text.lower() #converting to lower case. After this the complete review will be in lower case\n",
        "    String1 = BeautifulSoup(String1, \"lxml\").text\n",
        "    #Beautiful Soup is a Python library for pulling data out of HTML and XML files. It is used for tasks like extracting the\n",
        "    #entire text from a page, extracting all URLs found in a page\n",
        "    #We create a BeautifulSoup object by passing two arguments:newString(raw HTML content) and lxml(HTML parser we want to use)\n",
        "    String1 = re.sub(r'\\([^)]*\\)', '', String1)\n",
        "    #The re.sub() function in the re module can be used to replace substrings.\n",
        "    #The syntax for re.sub() is re.sub(pattern,repl,string).\n",
        "    #That will replace the matches in string with repl.\n",
        "    String1 = re.sub('\"','', String1)\n",
        "    String1 = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in String1.split(\" \")])\n",
        "    #The join() method is a string method and returns a string in which the elements of sequence have been joined by str separator.\n",
        "    #Here we join with an empty string.\n",
        "    #The above instruction removes contraction from the string.\n",
        "    String1 = re.sub(r\"'s\\b\",\"\",String1)\n",
        "    String1 = re.sub(\"[^a-zA-Z]\", \" \", String1)\n",
        "    String1 = re.sub('[m]{2,}', 'mm', String1)\n",
        "    #removes the stopwords\n",
        "    #tokens will be a list\n",
        "    if(num==0):\n",
        "        #for text remove the stop_words\n",
        "        tokens = [w for w in String1.split() if not w in stop_words]\n",
        "    else:\n",
        "        #for summary stop words cannot be removed because the summary is already small. So just take all words in summary as tokens\n",
        "        tokens=String1.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        #for each token if length of the token is less than one then eliminate the token/word\n",
        "        if len(i)>1:\n",
        "            long_words.append(i)\n",
        "    #join will convert the list back to string and strip() will remove leading spaces if any.\n",
        "    return (\" \".join(long_words)).strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI85BoFmusEj"
      },
      "source": [
        "Understanding the function text_cleaner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "93PPPiArusEk"
      },
      "outputs": [],
      "source": [
        "#Sample string to understand the use of contraction mapping and join function\n",
        "string=\"ABC ain't def ain't\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28hpfaw2usEk",
        "outputId": "8cb8a1fe-778e-4a11-fde5-cfaa9787b536"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ABC', 'is not', 'def', 'is not']"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "#split the words of a sentence at the \" \" (string.split(\" \"))\n",
        "#check each word if it is the key of the dictionary contraction_mapping then replace the key by the value\n",
        "#if not then keep the word as it is\n",
        "#string will be list of resultant words\n",
        "string =[contraction_mapping[t] if t in contraction_mapping else t for t in string.split(\" \")]\n",
        "string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Wr1Tc8x3usEl",
        "outputId": "96c28788-d74d-4bd6-d00d-b2ad2a473e8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ABC is not def is not'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "#to get the string back from list of words\n",
        "string=' '.join(string)\n",
        "string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Z36pDBaXusEl",
        "outputId": "30dff6db-3a4f-4e61-b568-3507146fea9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ABC is not def is not'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "#Join the list of words so obtanined with an empty string to convert back to string\n",
        "string = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in string.split(\" \")])\n",
        "string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BPzeLGVwusEl",
        "outputId": "503b58b8-a648-4f62-b13c-22891bdba924"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ABC is not def is not'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCfBisvOusEl",
        "outputId": "280012b1-1ac6-484e-b5f4-6533ca99edf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ABC', 'is', 'not', 'def', 'is', 'not']"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "string.split() #string bydefault splits at spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0nJzoumusEl",
        "outputId": "91d69816-5a51-4257-9da4-2fd2a1e63415"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ABC', 'def']"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "#This gives words which are not stopwords\n",
        "tokens = [w for w in string.split() if not w in stop_words]\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "tUlMnH8XusEm"
      },
      "outputs": [],
      "source": [
        "#redefining tokens to understand elimination of short words\n",
        "tokens=['I','am','a','girl']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkwxGdsCusEm",
        "outputId": "f852f9e2-e375-48a5-bae7-41bf14bc869f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['am', 'girl']"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "long_words=[]\n",
        "for i in tokens :\n",
        "    #Initially long words is a empty list\n",
        "    #Examine each token and if its length is greater than 1 then include it in the long_word list.\n",
        "    #In this way all the short words with length 0 or 1 are removed\n",
        "    if len(i)>1:\n",
        "        long_words.append(i)\n",
        "long_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1dQQq2gWusEm",
        "outputId": "b200e119-03b8-475c-f6d8-eaf61be41e38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'am girl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "\" \".join(long_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iT-IzBcwusEm",
        "outputId": "23c6f65a-ac19-4f0c-d464-d877276191c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'am girl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "\" \".join(long_words).strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMGfmCekusEn"
      },
      "source": [
        "Calling the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "MjUP4kUiusEn"
      },
      "outputs": [],
      "source": [
        "#call the function\n",
        "#cleaned_text is an empty string intially. For each entry i.e. row the text column value is\n",
        "#taken and cleaned by the function text_cleaner defined above. The cleaned text is added in the cleaned_text list.\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "-pPrbaSiusEn"
      },
      "outputs": [],
      "source": [
        "#The same function is called for the Summary column as well and in similar manner cleanned_summary list is generated.\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7e5fvArusEn",
        "outputId": "4bb797af-86bf-490f-e1d7-f27990c055d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
              " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
              " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
              " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal']"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "cleaned_text[0:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZNzGHWCusEn",
        "outputId": "185bd009-3bd4-4bd7-e675-c2eb418beb96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good quality dog food',\n",
              " 'not as advertised',\n",
              " 'delight says it all',\n",
              " 'cough medicine']"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "cleaned_summary[0:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "kviCeolNusEo"
      },
      "outputs": [],
      "source": [
        "#Adding two new columns namely cleaned_text and cleaned_summary in the data\n",
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrU46Q7cusEo"
      },
      "source": [
        "Drop ' '(Empty) rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "2Zr37JGRusEt"
      },
      "outputs": [],
      "source": [
        "#first replace blank spaces with NaN and then drop rows with NaN.\n",
        "#This can be called a trick to drop ' ' by using dropna\n",
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBDITpR0usEt"
      },
      "source": [
        "\n",
        "# Understanding the distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "jsbCi_53usEu"
      },
      "outputs": [],
      "source": [
        "#For plotting graphs\n",
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "for i in data['cleaned_text']:\n",
        "    #for each entry in cleaned_text the number of words are counted in the entry and the count is appended to text_word_count list\n",
        "    text_word_count.append(len(i.split()))\n",
        "for i in data['cleaned_summary']:\n",
        "    #for each entry in cleaned_summary the number of words are counted in the entry and the count is appended to summary_word_count list\n",
        "    summary_word_count.append(len(i.split()))\n",
        "#A dataframe with two columns is made. 1st column has entries of text_word_count and 2nd has entries of summart_word_count\n",
        "df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ghIymwpmusEu",
        "outputId": "97d7a51c-9484-409c-e634-0dcc3d7f16bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   text  summary\n",
              "0    23        4\n",
              "1    18        3\n",
              "2    39        4\n",
              "3    17        2\n",
              "4    13        2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6209831b-b91d-4c36-aadf-5f0bdcb708aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6209831b-b91d-4c36-aadf-5f0bdcb708aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6209831b-b91d-4c36-aadf-5f0bdcb708aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6209831b-b91d-4c36-aadf-5f0bdcb708aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2040c288-3aa3-4d3f-9dd9-804c60eed22c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2040c288-3aa3-4d3f-9dd9-804c60eed22c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2040c288-3aa3-4d3f-9dd9-804c60eed22c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "df.head() #by default 5 entries are displayed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "xLfouNpVusEu",
        "outputId": "6553a0e5-34d6-4be1-fe2e-85fcf3b6e76b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Plotting the histogram for the dataframe\n",
        "#Histogram plots the graph between values and frequencies\n",
        "df.hist(bins = 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXnhJqcxusEu"
      },
      "source": [
        "Lets find out the percentage of summaries below length=8,length=9 and length=10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcOWBR5PusEu"
      },
      "source": [
        "Find the appropriate max summary length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOT7Yc9SusEu",
        "outputId": "31a8ea66-37e3-4a21-ac90-9b167cb62d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9458130834941876\n"
          ]
        }
      ],
      "source": [
        "#initialize count with value 0\n",
        "#for each entry in cleaned summary, split the cleaned summary at spaces to find number of words and if the no. of word\n",
        "#are less than or equal to 8 then increement count\n",
        "#In this way count will have the count of cleaned summaries with number of words less than or equal to 8.\n",
        "count=0\n",
        "for i in data['cleaned_summary']:\n",
        "    if(len(i.split())<=8):\n",
        "        count=count+1\n",
        "print(count/len(data['cleaned_summary']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhag7LFeusEv",
        "outputId": "f930ac44-f6d7-49cc-d8b6-bca690ff3e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9668271394892844\n"
          ]
        }
      ],
      "source": [
        "#initialize count with value 0\n",
        "#for each entry in cleaned summary, split the cleaned summary at spaces to find number of words and if the no. of word\n",
        "#are less than or equal to 9 then increement count\n",
        "#In this way count will have the count of cleaned summaries with number of words less than or equal to 9.\n",
        "count=0\n",
        "for i in data['cleaned_summary']:\n",
        "    if(len(i.split())<=9):\n",
        "        count=count+1\n",
        "print(count/len(data['cleaned_summary']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar3NBEc3usEv",
        "outputId": "bb83c951-e344-48a9-d655-87f9d4ad8725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9801405345194589\n"
          ]
        }
      ],
      "source": [
        "#initialize count with value 0\n",
        "#for each entry in cleaned summary, split the cleaned summary at spaces to find number of words and if the no. of word\n",
        "#are less than or equal to 10 then increement count\n",
        "#In this way count will have the count of cleaned summaries with number of words less than or equal to 10.\n",
        "count=0\n",
        "for i in data['cleaned_summary']:\n",
        "    if(len(i.split())<=10):\n",
        "        count=count+1\n",
        "print(count/len(data['cleaned_summary']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJafJG1pusEv"
      },
      "source": [
        "Lets fix the max cleaned summary length to 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_SHdIZausEv"
      },
      "source": [
        "Find the appropriate max text length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5bmr4_JusEv",
        "outputId": "96f70437-23e5-47cd-ee5d-36bdc400f279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3570151546362913\n"
          ]
        }
      ],
      "source": [
        "#initialize count with value 0\n",
        "#foe each entry in cleaned text, split the cleaned text at spaces to find number of words and if the no. of word\n",
        "#are less than or equal to 20 then increement count\n",
        "#In this way count will have the count of cleaned texts with number of words less than or equal to 20.\n",
        "count=0\n",
        "for i in data['cleaned_text']:\n",
        "    if(len(i.split())<=20):\n",
        "        count=count+1\n",
        "print(count/len(data['cleaned_text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoN0AF1MusEv",
        "outputId": "5f2c1691-7390-470b-acb4-fbba226de027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.46853995162926965\n"
          ]
        }
      ],
      "source": [
        "#initialize count with value 0\n",
        "#foe each entry in cleaned text, split the cleaned text at spaces to find number of words and if the no. of word\n",
        "#are less than or equal to 25 then increement count\n",
        "#In this way count will have the count of cleaned texts with number of words less than or equal to 25.\n",
        "count=0\n",
        "for i in data['cleaned_text']:\n",
        "    if(len(i.split())<=25):\n",
        "        count=count+1\n",
        "print(count/len(data['cleaned_text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVX_rbY7usEw",
        "outputId": "280b73d9-a0db-47da-ffe4-9f68f189345a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6337455780963498\n"
          ]
        }
      ],
      "source": [
        "#initialize count with value 0\n",
        "#foe each entry in cleaned text, split the cleaned text at spaces to find number of words and if the no. of word\n",
        "#are less than or equal to 35 then increement count\n",
        "#In this way count will have the count of cleaned texts with number of words less than or equal to 35.\n",
        "count=0\n",
        "for i in data['cleaned_text']:\n",
        "    if(len(i.split())<=35):\n",
        "        count=count+1\n",
        "print(count/len(data['cleaned_text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlR6r2JMusEw",
        "outputId": "fb4fee83-2404-4d91-da0d-e43be7d65078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7432612858679647\n"
          ]
        }
      ],
      "source": [
        "#initialize count with value 0\n",
        "#foe each entry in cleaned text, split the cleaned text at spaces to find number of words and if the no. of word\n",
        "#are less than or equal to 45 then increement count\n",
        "#In this way count will have the count of cleaned texts with number of words less than or equal to 45.\n",
        "count=0\n",
        "for i in data['cleaned_text']:\n",
        "    if(len(i.split())<=45):\n",
        "        count=count+1\n",
        "print(count/len(data['cleaned_text']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7gp1ulDusEw"
      },
      "source": [
        "Lets fix the max text length as 45"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O8NncyRusEw"
      },
      "source": [
        "Now selecting those entries in which cleaned text length is less than equal to 45 and cleaned summary length is less than equal to 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "FYsCpnp0usEw"
      },
      "outputs": [],
      "source": [
        "max_summary_len=10\n",
        "max_text_len=45"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "7t2AKWmHusEx"
      },
      "outputs": [],
      "source": [
        "#making array of cleaned text entries and cleaned summary entries\n",
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "#short_text and short_summary are initially empty but will contain all the text and summary entries which fall in the desired range\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    #For all entries if the cleaned_summary has no. of words <=max summary length which is equal to 10\n",
        "    #and cleaned_text has no. of words <=max text length which is equal to 45 add such entries to the lists short_text and short_summary\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "#create a dataframe to store the results of short_text and short_summary\n",
        "df1=pd.DataFrame({'text':short_text,'summary':short_summary})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "2dLgBfb-usEx",
        "outputId": "d98a3173-1a32-4930-93b3-0a37db3c6fe8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                      text  \\\n",
              "0                                     bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better   \n",
              "1                                                                    product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo   \n",
              "2  confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...   \n",
              "3                                                                              looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal   \n",
              "4                                                                                                                      great taffy great price wide assortment yummy taffy delivery quick taffy lover deal   \n",
              "\n",
              "                 summary  \n",
              "0  good quality dog food  \n",
              "1      not as advertised  \n",
              "2    delight says it all  \n",
              "3         cough medicine  \n",
              "4            great taffy  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5896ddb-66f8-4db3-b3c1-5d8b21d47fea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better</td>\n",
              "      <td>good quality dog food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo</td>\n",
              "      <td>not as advertised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...</td>\n",
              "      <td>delight says it all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal</td>\n",
              "      <td>cough medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great taffy great price wide assortment yummy taffy delivery quick taffy lover deal</td>\n",
              "      <td>great taffy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5896ddb-66f8-4db3-b3c1-5d8b21d47fea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a5896ddb-66f8-4db3-b3c1-5d8b21d47fea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a5896ddb-66f8-4db3-b3c1-5d8b21d47fea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e75fcc6d-ed71-4f81-ae1c-752093c53047\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e75fcc6d-ed71-4f81-ae1c-752093c53047')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e75fcc6d-ed71-4f81-ae1c-752093c53047 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUqcxc3BusEx"
      },
      "source": [
        "Now add the start and end token to each summary. This can be done using lambda function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "GNs0b65yusEx"
      },
      "outputs": [],
      "source": [
        "#This will replace each summary with 'starttoken' as start token concatenated with summary concatenated with 'endtoken' as end token\n",
        "#Be sure that the chosen special tokens never appear in the summary\n",
        "df1['summary'] = df1['summary'].apply(lambda x : 'starttoken '+ x + ' endtoken')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oIDoyjZusEx"
      },
      "source": [
        "Now splitting data into training and testing sets. Take 90% of the dataset as the training data and evaluate the performance on the remaining 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "qvCNLmUuusEy"
      },
      "outputs": [],
      "source": [
        "#Sklearn is used to perform the split. This is standard technique to split the dataset.Test size is set to 0.1 i.e. 10%.\n",
        "#x variable is text\n",
        "#y variable is summary\n",
        "#df['text'] and df['summary'] contain respective reviews and summaries in form of array\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(np.array(df1['text']),np.array(df1['summary']),test_size=0.1,random_state=0,shuffle=True)\n",
        "#xtrain,x_test,y_train,y_test all are numpy arrays containing reviews and summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ5B9EEBusEy"
      },
      "source": [
        "# Preparing the Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "88ROMtTZusEy",
        "outputId": "1f276917-e42f-491c-9ad2-c7d216147d9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a great product for money. I will recommend you to buy this'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "check=np.array([\"This is a great product for money. I will recommend you to buy this\"])\n",
        "check[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcnQ1_tQusEy"
      },
      "source": [
        "# Text Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "FtSQIaGDusEy"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "AwOumFnIusEy"
      },
      "outputs": [],
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "t = Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKVA_YNVusEz",
        "outputId": "b0d2d550-7ac2-4d76-941c-a9a82016fe4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.preprocessing.text.Tokenizer at 0x7932a02cc730>"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ],
      "source": [
        "t\n",
        "#Output would be  <keras_preprocessing.text.Tokenizer at 0x217e980deb8>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "fcXaEqi3usEz"
      },
      "outputs": [],
      "source": [
        "#tokenizing x_train. First x_train which is a numpy array is converted to list\n",
        "t.fit_on_texts(list(x_train))\n",
        "#fit_on_texts Updates internal vocabulary based on a list of texts.\n",
        "#This method creates the vocabulary index based on word frequency.\n",
        "#So if you give it something like, \"The cat sat on the mat.\"\n",
        "#It will create a dictionary s.t. word_index[\"the\"] = 1;\n",
        "#word_index[\"cat\"] = 2 it is word -> index dictionary so every word gets a unique integer value.\n",
        "#0 is reserved for padding.\n",
        "#So lower integer means more frequent word (often the first few are stop words because they appear a lot)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "555B_vz0usEz"
      },
      "source": [
        "Rarewords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "risM6XjpusEz",
        "outputId": "8fb401d7-9bf3-4ee0-a22a-a91613cf26f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44773\n",
            "72099\n",
            "% of rare words in vocabulary: 62.09933563572311\n",
            "Total Coverage of rare words: 0.8957585961931777\n"
          ]
        }
      ],
      "source": [
        "#Rare words are those words which do not appear too often\n",
        "#Defining the threshold as 3. If the words apear less than thrice then the word are rare words.\n",
        "threshold=3\n",
        "#count has count of rare words\n",
        "count=0\n",
        "#totalcount has the count of total number of words i.e. size of vocabulary\n",
        "totalcount=0\n",
        "#frequency has total frequency of all the rare words\n",
        "frequency=0\n",
        "#totalfrequency has the sum of all frequencies of all words\n",
        "totalfrequency=0\n",
        "#t.word_counts.items() will give items of ordered dictionary i.e.  'key' and 'value' pair. key being the word and value being the number of times it ocuured.\n",
        "#odict_items([('love', 45148), ('raspberry', 1096), ('shortbread', 276), ('cookies', 6596), ('easy', 10588), ('find', 21556), ....\n",
        "for key,value in t.word_counts.items():\n",
        "    #accessing each key value pair\n",
        "    #totalcount is increemented by 1 as the word encountered is a new word add totalcount by 1\n",
        "    totalcount=totalcount+1\n",
        "    #totalfrequency is increemneted by value\n",
        "    totalfrequency=totalfrequency+value\n",
        "    #if value is less than threshold than it is rare word and count is incremented by 1 and frequency by value.\n",
        "    if(value<threshold):\n",
        "        count=count+1\n",
        "        frequency=frequency+value\n",
        "print(count)\n",
        "print(totalcount)\n",
        "# %of rare words is (number of rare words divided by total number of words) multiplied by 100 i.e. (count divided by totalcount) multiplied by 100\n",
        "print(\"% of rare words in vocabulary:\",(count/totalcount)*100)\n",
        "# coverage of rare words is (frequency divided by total frequency) multiplied by 100\n",
        "print(\"Total Coverage of rare words:\",(frequency/totalfrequency)*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "kRfD7hgyusEz"
      },
      "outputs": [],
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "#totalcount-count is number of common words\n",
        "#Only common words will be remembered\n",
        "x_tokenizer = Tokenizer(num_words=totalcount-count)\n",
        "x_tokenizer.fit_on_texts(list(x_train))\n",
        "#x_tokenizer.word_index will give\n",
        "#{'like': 1,'good': 2, 'great': 3,'taste': 4, 'product': 5,'love': 6,'one': 7,....\n",
        "#This means like appers is the most common word followed by good then great and so on\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_train_sequence    =   x_tokenizer.texts_to_sequences(x_train)\n",
        "#only common words will be remembered\n",
        "x_test_sequence   =   x_tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "#pad_sequences is used to ensure that all sequences in a list have the same length.\n",
        "#By default this is done by padding 0 in the beginning of each sequence until each sequence has the same length as the longest sequence.\n",
        "#Here zeros are padded at the end\n",
        "x_train   =   pad_sequences(x_train_sequence,  maxlen=max_text_len,padding='post')\n",
        "x_test   =   pad_sequences(x_test_sequence, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YyEXZuJusE0",
        "outputId": "b3c39595-8f26-4af5-cce9-1c44a432ad5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27327"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "x_voc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FjfY-3lusE0"
      },
      "source": [
        "For understanding Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "Uo0jahxtusE0"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "texts = ['a a a', 'b b b b b', 'c c c c c c c','ddd','aa a','aa aa']\n",
        "#'a a a' is a string with 3 words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "3wV4sGyousE0"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=4)\n",
        "#num_words: the maximum number of words to keep, based on word frequency.\n",
        "#Only the most common num_words-1 words will be kept.\n",
        "#Tokenizer will use only three most common words and at the same time, it will keep the counter of all words - even when it's obvious that it will not use it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "35vyb2byusE0"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0q2SAndusE1",
        "outputId": "3bb96061-8479-44c6-9062-e5c922bdfdd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'c': 1, 'b': 2, 'a': 3, 'aa': 4, 'ddd': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "tokenizer.word_index\n",
        "#c is the most common word so will get the value 1.\n",
        "#b will get value 2\n",
        "#a will get 3\n",
        "#aa will get 4\n",
        "#ddd will get 5\n",
        "#More times a number appears lesser will be its key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA_S0GZmusE1",
        "outputId": "cd610acb-dd0f-4f4c-eb79-7c8b237c2f86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 3, 3], [2, 2, 2, 2, 2], [1, 1, 1, 1, 1, 1, 1], [], [3], []]"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences(texts)\n",
        "#only c,b,and a will be remembered\n",
        "#See \"aa a\" i.e. 4th index only a is remembered and aa is not so only 3 is the answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spOIgo9zusE1"
      },
      "source": [
        "# Summary Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "p20LRwznusE1"
      },
      "outputs": [],
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "t1= Tokenizer()\n",
        "t1.fit_on_texts(list(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJCFfK-NusE1",
        "outputId": "edf8858b-ee7a-4cc7-896d-c0d63768c413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51650\n",
            "72099\n",
            "% of rare words in vocabulary: 71.6376093981886\n",
            "Total Coverage of rare words: 1.2895532752037442\n"
          ]
        }
      ],
      "source": [
        "#Doing the similar thing with summary\n",
        "#Threshold is set to 5\n",
        "threshold=5\n",
        "count=0\n",
        "totalcount=0\n",
        "frequency=0\n",
        "totalfrequency=0\n",
        "\n",
        "for key,value in t.word_counts.items():\n",
        "    totalcount=totalcount+1\n",
        "    totalfrequency=totalfrequency+value\n",
        "    if(value<threshold):\n",
        "        count=count+1\n",
        "        frequency=frequency+value\n",
        "print(count)\n",
        "print(totalcount)\n",
        "print(\"% of rare words in vocabulary:\",(count/totalcount)*100)\n",
        "print(\"Total Coverage of rare words:\",(frequency/totalfrequency)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "LbqyrsZmusE2"
      },
      "outputs": [],
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=totalcount-count)\n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_train_sequence=y_tokenizer.texts_to_sequences(y_train)\n",
        "y_test_sequence=y_tokenizer.texts_to_sequences(y_test)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_train=pad_sequences(y_train_sequence, maxlen=max_summary_len, padding='post')\n",
        "y_test=pad_sequences(y_test_sequence, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc=y_tokenizer.num_words +1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I84lqSNHusE2",
        "outputId": "65478516-6d7b-4304-b4f0-042dbf92c3db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1178,    1,  685, ...,    0,    0,    0],\n",
              "       [  78,  155,  270, ...,    0,    0,    0],\n",
              "       [  15,  466, 1142, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 450,  105,   82, ...,    0,    0,    0],\n",
              "       [ 178,    6,  249, ...,    0,    0,    0],\n",
              "       [  15,  510,   37, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ],
      "source": [
        "x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aoie0xYusE2",
        "outputId": "fbd4bb57-0eb9-4b0c-85a1-57b9334b2ca9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20450"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ],
      "source": [
        "y_voc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMrFKTJmusE3",
        "outputId": "01d742ce-a263-4160-b825-cd9a7f45e94d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(259944, 259944)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ],
      "source": [
        "#The number of times startoken appears should be equal to length of training data\n",
        "y_tokenizer.word_counts['starttoken'],len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "-NYHk52musE3"
      },
      "outputs": [],
      "source": [
        "#Deleting those rows which only contain start and end token\n",
        "empty=[]\n",
        "#Checking each element of y train. Each element of y train is a list in itself.\n",
        "for i in range(len(y_train)):\n",
        "    count=0\n",
        "    for j in y_train[i]:\n",
        "        #checking each element in one element of y_train\n",
        "            count=count+1\n",
        "    if(count==2):\n",
        "        #if there are only 2 non zero elements that is start and end token then the list is actualy empty and append that index\n",
        "        #in empty list so that we can delete those rows\n",
        "        empty.append(i)\n",
        "\n",
        "#Deleting x and y  for those indices present in empty list that is those rows which only have start and end token\n",
        "y_train=np.delete(y_train,empty, axis=0)\n",
        "x_train=np.delete(x_train,empty, axis=0)\n",
        "#Axis is 0 because rows have to be deleted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "wqtGq8PXusE3"
      },
      "outputs": [],
      "source": [
        "#Deleting those rows which only contain start and end token\n",
        "empty=[]\n",
        "for i in range(len(y_test)):\n",
        "    count=0\n",
        "    for j in y_test[i]:\n",
        "        if j!=0:\n",
        "            count=count+1\n",
        "    if(count==2):\n",
        "        empty.append(i)\n",
        "\n",
        "y_test=np.delete(y_test,empty, axis=0)\n",
        "x_test=np.delete(x_test,empty, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBAsQR81usE4"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "9S925yOSusE4"
      },
      "outputs": [],
      "source": [
        "#Return Sequences = True: When the return sequences parameter is set to True, LSTM produces the hidden state and cell state for every timestep\n",
        "\n",
        "#Return State = True: When return state = True, LSTM produces the hidden state and cell state of the last timestep only\n",
        "\n",
        "#Initial State: This is used to initialize the internal states of the LSTM for the first timestep\n",
        "\n",
        "#Stacked LSTM: Stacked LSTM has multiple layers of LSTM stacked on top of each other. This leads to a better representation of the sequence. I encourage you to experiment with the multiple layers of the LSTM stacked on top of each other (it’s a great way to learn this)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deVkcbhpusE8",
        "outputId": "82802154-da69-4b87-b411-64a1b6dc81ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 45)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 45, 100)              2732700   ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 45, 300),            481200    ['embedding[0][0]']           \n",
            "                              (None, 300),                                                        \n",
            "                              (None, 300)]                                                        \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, 45, 300),            721200    ['lstm[0][0]']                \n",
            "                              (None, 300),                                                        \n",
            "                              (None, 300)]                                                        \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 100)            2045000   ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               [(None, 45, 300),            721200    ['lstm_1[0][0]']              \n",
            "                              (None, 300),                                                        \n",
            "                              (None, 300)]                                                        \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               [(None, None, 300),          481200    ['embedding_1[0][0]',         \n",
            "                              (None, 300),                           'lstm_2[0][1]',              \n",
            "                              (None, 300)]                           'lstm_2[0][2]']              \n",
            "                                                                                                  \n",
            " attention (Attention)       (None, 45, 300)              0         ['lstm_2[0][0]',              \n",
            "                                                                     'lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)  (None, None, 300)            0         ['lstm_3[0][0]',              \n",
            "                                                                     'attention[0][0]']           \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, None, 20450)          6155450   ['concat_layer[0][0]']        \n",
            " ributed)                                                                                         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13337950 (50.88 MB)\n",
            "Trainable params: 13337950 (50.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "import tensorflow as tf\n",
        "# attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out = tf.keras.layers.Attention()([encoder_outputs, decoder_outputs])\n",
        "# attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "# decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "decoder_concat_input = Concatenate(axis=1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "kO0bpwSwusE9"
      },
      "outputs": [],
      "source": [
        "# model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "RAsHHvW1usE9"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
        "#If the validation loss increases then stop the model early"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHRjOBQKw_y_",
        "outputId": "41d9d1e1-08fd-4945-c3ca-b29d0ccdfed5"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(259944, 45)\n",
            "(259944, 10)\n",
            "(28700, 45)\n",
            "(28700, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "m3sVbLX2usE9",
        "outputId": "fc4d2527-22c8-4157-fe49-f5961b684d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 9, 1) and (None, 54, 20450) are incompatible\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-185-4206c6637772>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 9, 1) and (None, 54, 20450) are incompatible\n"
          ]
        }
      ],
      "source": [
        "history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCAy4zWEusE-"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxMX_KYQusE-"
      },
      "outputs": [],
      "source": [
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "#As it is visible that validation loss decresed till 25 epochs and then it remained constant in 26th epoch so"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VnYEFeTusE-"
      },
      "outputs": [],
      "source": [
        "y_tokenizer.index_word\n",
        "#starttoken and endtoken have the most frequency because they appear in each summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx2UvOXausE_"
      },
      "outputs": [],
      "source": [
        "x_tokenizer.index_word\n",
        "#'like' is most frequent in review followed by 'good' and so on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kA7zccn3usE_"
      },
      "outputs": [],
      "source": [
        "y_tokenizer.word_index\n",
        "#difference between word_index and index_word is that in word_index word comes first followed by index whereas in index_word it is the opposite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40vxEf_pusE_"
      },
      "outputs": [],
      "source": [
        "y_index_word=y_tokenizer.index_word\n",
        "x_index_word=x_tokenizer.index_word\n",
        "y_word_index=y_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKa9wpiTusE_"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHIogyiHusFA"
      },
      "outputs": [],
      "source": [
        "# For building the model 3 LSTM encoder layers were used along with decoder\n",
        "#Now model is decoded\n",
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIf9988nusFA"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    #It is an array of one row and one column\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    #target_seq will be array of one row and one column with value as 1\n",
        "    target_seq[0, 0] = y_word_index['starttoken']\n",
        "    #initializing stop condition to be false\n",
        "    stop_condition = False\n",
        "    #decode sentence initially is empty\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = y_index_word[sampled_token_index]\n",
        "\n",
        "        if(sampled_token!='endtoken'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'endtoken'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k1-IlvDusFA"
      },
      "source": [
        "Understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UmBL4f4usFA"
      },
      "outputs": [],
      "source": [
        "target_seq = np.zeros((1,1))\n",
        "target_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLSCb9L4usFB"
      },
      "outputs": [],
      "source": [
        "target_seq[0, 0] = y_word_index['starttoken']\n",
        "target_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgFLx9aOusFB"
      },
      "outputs": [],
      "source": [
        "x=np.arange(8)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx5x18VFusFB"
      },
      "outputs": [],
      "source": [
        "x.reshape(1,8)\n",
        "# 1 D array converted to 2D array with one row and 8 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTdoQDaYusFB"
      },
      "outputs": [],
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=y_word_index['starttoken']) and i!=y_word_index['endtoken']):\n",
        "            newString=newString+y_index_word[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+x_index_word[i]+' '\n",
        "    return newString"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1DVAA5GusFB"
      },
      "outputs": [],
      "source": [
        "for i in range(0,100):\n",
        "    print(\"Review:\",seq2text(x_train[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_train[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_train[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhMy4kMhusFC"
      },
      "outputs": [],
      "source": [
        "for i in range(0,100):\n",
        "    print(\"Review:\",seq2text(x_test[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_test[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_test[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD7sKhXnusFC"
      },
      "outputs": [],
      "source": [
        "check=np.array([\"This is a great product for money. I ordered it for my sister and she loved the product. She is very happy and so am I\"])\n",
        "check_seq=x_tokenizer.texts_to_sequences(check)\n",
        "check_test=pad_sequences(check_seq, maxlen=max_text_len, padding='post')\n",
        "print(\"Predicted summary:\",decode_sequence(check_test[0].reshape(1,max_text_len)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}